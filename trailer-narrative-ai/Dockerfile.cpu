# Trailer Narrative AI - CPU-Only Docker Configuration
# For systems without NVIDIA GPU
#
# Build: docker build -f Dockerfile.cpu -t trailer-narrative-ai:cpu .
# Run:   docker run -v /path/to/input:/app/input -v /path/to/output:/app/output trailer-narrative-ai:cpu /app/input/movie.mp4

FROM python:3.11-slim

# Build arguments
ARG WHISPER_MODEL=medium
ARG LLM_MODEL=google/flan-t5-large

# Labels
LABEL maintainer="Stage Tech"
LABEL version="3.0.0"
LABEL description="CPU-only trailer generation (slower but no GPU required)"

# Install system dependencies
RUN apt-get update && apt-get install -y \
    ffmpeg \
    libsm6 \
    libxext6 \
    libgl1-mesa-glx \
    git \
    && rm -rf /var/lib/apt/lists/*

# Set working directory
WORKDIR /app

# Copy requirements first for better caching
COPY requirements.txt .

# Install CPU-only PyTorch and dependencies
RUN pip install --no-cache-dir --upgrade pip && \
    pip install --no-cache-dir torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu && \
    pip install --no-cache-dir -r requirements.txt

# Pre-download Whisper model
RUN python3 -c "import whisper; whisper.load_model('${WHISPER_MODEL}')"

# Pre-download LLM model
RUN python3 -c "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer; \
    AutoTokenizer.from_pretrained('${LLM_MODEL}'); \
    AutoModelForSeq2SeqLM.from_pretrained('${LLM_MODEL}')"

# Copy application code
COPY . .

# Create directories
RUN mkdir -p /app/output /app/input /tmp/trailer-narrative-ai

# Set environment variables
ENV PYTHONUNBUFFERED=1
ENV PYTHONDONTWRITEBYTECODE=1

# Force CPU device
ENV WHISPER_DEVICE=cpu
ENV VISUAL_DEVICE=cpu
ENV LLM_DEVICE=cpu

# LLM configuration
ENV USE_LLM=true
ENV LLM_MODEL=${LLM_MODEL}

# Processing configuration
ENV ASR_CHUNKED=false
ENV MAX_WORKERS=1

# Production settings
ENV ENVIRONMENT=production

# Entry point
ENTRYPOINT ["python3", "main.py"]
